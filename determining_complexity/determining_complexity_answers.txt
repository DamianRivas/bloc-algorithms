1. Big-O of the "Goodbye World" program is constant time. It does not iterate
through a collection and performs just one constant time operation.

2. The function iterates through the collection starting from the first element
and it looks for the largest item. The worst case scenario is when the largest
item is the last, or the nth element in the collection, and every other operation
is a constant time operation. So, this function has a Big-O of n.

3. This function iterates througm
gh a two-dimensional array starting at [0][0] and
it looks for the largest item. The worst case scenario is when the largest item
is sitting at the end-most location.

If n is the total number of items then the worst case scenario in this algorithm
is still just n despite there being two for loops. This is because the algorithm
will iterate n times at most before finding the largest item. This is also the
best case scenario.

4. I wrote a function to print out the number of times `numbers` recursively calls
itself for a range of n. You can run the `recursive_fib_test.rb` file to check it
out. The base cases are obviously constant time, but things get interesting after
n=1. For n=2 and n=3 it seems that it has a Big-O of 2^n. After that, it seems to
be 2^(n) + c where c is a very small constant up until around n=8 where the
performance actually improves relative to n. So the worst case is definitely
around 2^n making that the Big-O.

5. This algorithm has a Big-O of n. There is one while loop that iterates n-2 times.
All the other operations are constant time. So we have:
f(n) = n - 2 + c
Where c stands for the constant time operations. We only keep the largest term
leaving us with f(n) = n

6. For this final algorithm, the worst case is when the first call to `sort` is on
the entire collection. Assume everything described from now on only happens in the
worst case (ignoring early returns and more). The algorithm starts with a couple of
constant time operations before leading up to a `while` loop.

The while loop iterates through the whole collection with some constant time
operations, so far the Big-O is at least n.

Then, `sort` is recursively called for the collections on either side of the pivot.
This means overall the process repeats itself every time with a sub-collection of
n-1 until the size of the sub-collection is 1 or 0. This means the Big-O of `sort`
is n! (n prime).

By the way, it doesn't actually sort properly so I don't know if this was done on
purpose.
